#!/bin/bash

################################################################
# This file is for submitting time series plot job into condor.
#
# $condir will be used as output directory.
#
# Recommendation: 
# 
# In python script, package Kozapy/samples/mylib/ is reuired.
# Please make symbolic link in your working directory like this. 
# $ ln -s /path/to/Kozapy/samples/mylib/ mylib
#
# Edit your ~/.bashrc file and insert the output directory.
#  export condir=~/path/to/output/directory/
# If $condir is empty, current directory will be used.
################################################################

# Define variables.

nametime="timeseries"
namespectrum="spectrum"
namespectrogram="whitening_spectrogram"
namecoherencegram="coherencegram"

cat $1 | while read gpstime channel min_duration max_duration bandwidth dump1 dump2 dump3 dump4 eventtype
do
    echo "gps time = $gpstime "
    echo "channel = $channel "
    echo "min_duration = $min_duration "
    echo "max_duration = $max_duration "
    echo "bandwidth = $bandwidth "

    # $index will be added to the output file name to distinguish from others. 
    index=$eventtype"_"$gpstime"_"$channel

    # channel list file can be generated by hand or by chlist.sh.
    # chlist.sh will not rewrite existing file. 
    channels=$channel".dat"
    ./chlist_plotter.sh $channels $channel

    # For timeseries, gps time start from 2s before glitch and end at 2s after glitch.
    
    # For spectrum, spectogram, and coherencegram,
    # fftlength is defined based on bandwidth of the trigger event.
    # For spectrum, fft length = 1/bandwidth, rounded to integer.
    fft30=`echo "scale=5; 1. / $bandwidth" | bc | awk '{printf("%d\n",$1 + 1)}'`
    # determine time scale to use. around 30s, use a nice round number.
    # divide is number of bins. 
    ndivide30=`echo "scale=5; 30. / $fft30" | bc | awk '{printf("%d\n",$1 + 1)}'`
    # span is total data length.
    span30=`echo "scale=5; $fft30 * $ndivide30" | bc `

    # for spectrogram etc.
    # fft length = larger one of [min_duration] or [max_duration/10]
    # stride = multiple of fft length, 

    # 
    fft=`echo "scale=5; $max_duration / 10. " | bc `
    echo fft $fft
    if [ "$(echo "$fft < $min_duration" | bc)" -eq 1 ]; then
	fft=$min_duration
    fi
    echo fft $fft


    # stride is minimum of a and b.

    a=`echo "scale=5; $min_duration * 10. " | bc `
    b=`echo "scale=5; $max_duration / 2. " | bc `
    stride=0
    span=0


    if [ "$(echo "$b < $a" | bc)" -eq 1 ]; then
	stride=$b
    else
	stride=$a
    fi

    divide=`echo "scale=5; $stride / $fft" | bc | awk '{printf("%d\n",$1 + 2)}'`

    # make the stride to be multiple of fft length.
    stride=`echo "scale=5; $fft * $divide" | bc `
    
    # make the time span to be multiple of stride.
    span=`echo "scale=5; $max_duration * 10 " | bc `
    if [ "$(echo "$span < 1.0" | bc)" -eq 1 ]; then
	span=1.
    fi

    divide=`echo "scale=5; $span / $stride" | bc | awk '{printf("%d\n",$1 + 1)}'`
    span=`echo "scale=5; $stride * $stride" | bc | awk '{printf("%d\n",$1 + 1)}'`

    tmpend=`echo "scale=5; $span30 + 2. " | bc `

    #    gpsstart=`expr $gpstime - 30`
#    gpsend=`expr $gpstime + 30`

    gpsstart=`echo "scale=5; $gpstime - $span " | bc `
    gpsend=`echo "scale=5; $gpstime + $span " | bc `

    gpsstart1=`echo "scale=5; $gpstime + 2. " | bc `
    gpsend1=`echo "scale=5; $gpstime + $span30 + 2. " | bc `
    gpsstart2=`echo "scale=5; $gpstime - $span30 - 2. " | bc `
    gpsend2=`echo "scale=5; $gpstime - 2. " | bc `
    gpsstarts30=($gpsstart1 $gpsstart2)
    gpsends30=($gpsend1 $gpsend2)

    # Data type for time series. Default is to use minutes trend. second trend or full data can be used with following flags. Please set one of them true and set the others false. Or it will give warning message and exit. 
    #data="minute"
    #data="second"
    data="full"

    kamioka=true
    #kamioka=false

    # For locked segments bar plot.
    lock=true
    #lock=false

    # IMC lock
    #lchannel="K1:GRD-IO_STATE_N.mean"  #guardian channel
    #lchannel="K1:GRD-IO_STATE_N"  #guardian channel
    #lnumber=99  #number of the required state
    #llabel='IMC_LSC'  #y-axis label for the bar plot.

    # X-arm lock
    lchannel="K1:GRD-LSC_LOCK_STATE_N"  #guardian channel
    lnumber=31415  #number of the required state
    llabel='X-arm'  #y-axis label for the bar plot.

    
    # Set the output directory.
#    condir="/users/.ckozakai/KashiwaAnalysis/analysis/code/gwpy/trigger/plotter"

    condir="/users/DET/Result/GlitchPlot"
    if [ "$condir" = "" ]; then
	condir=$PWD
    fi

    [ -e /usr/bin/gpstime ] && cmd_gps=/usr/bin/gpstime || cmd_gps=/home/controls/bin/gpstime
    date=`${cmd_gps} ${gpstime}| head -1`
    set ${date}
    date=`echo ${2}| sed -e 's/-//g'`

    outdir="$condir/$date/${index}/"

    # Confirm the existance of output directory.

    if [ ! -e $outdir ]; then
	mkdir -p $outdir
    fi

    {
	echo $gpstime $channel $min_duration $max_duration $bandwidth $dump1 $dump2 $dump3 $dump4 $eventtype
    } > $outdir/parameter.txt

    logdir="$PWD/log/"
    if [ ! -e $logdir ]; then
	mkdir -p $logdir
    fi

    # make main script.

    # for time series.

    Kozapy="/users/DET/tools/GlitchPlot/Script/Kozapy/samples"
    runtime="$PWD/run_${nametime}.sh"
    pytime="$Kozapy/batch_${nametime}.py"
    #py="~/batch_timesries.py"  # For the case you use non-conventional python script name.

    {
	echo "#!/bin/bash"
	echo ""
	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
	echo "# This file is generated from `basename $0`."
	echo "# If you need to change, please edit `basename $0`."
	echo ""
	echo "echo \$@"
	echo "python $pytime \$@"
	
    } > $runtime

    chmod u+x $runtime

    # Write a file for condor submission.
    
    {
	echo "Executable = ${runtime}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
    } > job_${nametime}.sdf

    # for spectrum series.
    
    runspectrum="$PWD/run_${namespectrum}.sh"
    pyspectrum="$Kozapy/batch_${namespectrum}.py"
    #py="~/batch_spectrumsries.py"  # For the case you use non-conventional python script name.

    {
	echo "#!/bin/bash"
	echo ""
	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
	echo "# This file is generated from `basename $0`."
	echo "# If you need to change, please edit `basename $0`."
	echo ""
	echo "echo \$@"
	echo "python $pyspectrum \$@"
	
    } > $runspectrum

    chmod u+x $runspectrum

    # Write a file for condor submission.
    
    {
	echo "Executable = ${runspectrum}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
    } > job_${namespectrum}.sdf

    # for spectrogram series.
    
    runspectrogram="$PWD/run_${namespectrogram}.sh"
    pyspectrogram="$Kozapy/batch_${namespectrogram}.py"
    #py="~/batch_spectrogramsries.py"  # For the case you use non-conventional python script name.

    {
	echo "#!/bin/bash"
	echo ""
	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
	echo "# This file is generated from `basename $0`."
	echo "# If you need to change, please edit `basename $0`."
	echo ""
	echo "echo \$@"
	echo "python $pyspectrogram \$@"
	
    } > $runspectrogram

    chmod u+x $runspectrogram

    # Write a file for condor submission.
    
    {
	echo "Executable = ${runspectrogram}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
    } > job_${namespectrogram}.sdf

        # for coherencegram series.
    
    runcoherencegram="$PWD/run_${namecoherencegram}.sh"
    pycoherencegram="$Kozapy/batch_${namecoherencegram}.py"
    #py="~/batch_coherencegramsries.py"  # For the case you use non-conventional python script name.

    {
	echo "#!/bin/bash"
	echo ""
	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
	echo "# This file is generated from `basename $0`."
	echo "# If you need to change, please edit `basename $0`."
	echo ""
	echo "echo \$@"
	echo "python $pycoherencegram \$@"
	
    } > $runcoherencegram

    chmod u+x $runcoherencegram

    # Write a file for condor submission.
    
    {
	echo "Executable = ${runcoherencegram}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
    } > job_${namecoherencegram}.sdf

    # Loop over each plot. 
    option=""
    if "${kamioka}" ; then
	option+=" -k"
    fi

    optionspectrum=$option
    
    if "${lock}" ; then
	option+=" -l ${lchannel} -n ${lnumber} --llabel ${llabel}"
    else
	echo "lock is false."
    fi

    optionspectrogram=$option
    optioncoherencegram=$option
    
    if [ $data = "minute" ] ; then
	option+=" -d minute"
    elif [ $data = "second" ] ; then
	option+=" -d second"
    elif [ $data = "full" ] ; then
	option+=" -d full"
    fi

    optiontime=$option

    cat $channels | while read chlist
    do
	# timeseries job
	{
	    # Please try
	    #  $ python batch_timeseries.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s $gpsstart -e $gpsend -o ${outdir} -i ${index} ${optiontime}"
	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
	    echo "Queue"
	} >> job_${nametime}.sdf
	
	# spectrum job
	{
	    # Please try
	    #  $ python batch_spectrum.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s ${gpsstarts30[@]} -e ${gpsends30[@]} -o ${outdir} -i ${index} -t time -f ${fft30} ${optionspectrum}"
	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
	    echo "Queue"
	} >> job_${namespectrum}.sdf

	# spectrogram job
	{
	    # Please try
	    #  $ python batch_ehitening_spectrogram.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i ${index} -f ${fft} --stride ${stride} ${optionspectrogram}"
	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
	    echo "Queue"

	    echo "Arguments = -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i ${index} -f ${fft} --stride ${stride} ${optionspectrogram} -w"
	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
	    echo "Queue"


	} >> job_${namespectrogram}.sdf

	# coherencegram job
	{
	    # Please try
	    #  $ python batch_coherencegram.py -h
	    # for option detail.
	    
	    echo "Arguments = -r $channel -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i ${index} -f ${fft} --stride ${stride} ${optioncoherencegram}"
	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
	    echo "Queue"

#	    echo "Arguments = -r $channel -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i ${index}dur -f ${duration} --stride ${durstride} ${optioncoherencegram}"
#	    echo "Output       = log/out_\$(Cluster).\$(Process).txt"
#	    echo "Error        = log/err_\$(Cluster).\$(Process).txt"
#	    echo "Log          = log/log_\$(Cluster).\$(Process).txt"
#	    echo "Queue"
} >> job_${namecoherencegram}.sdf

#	done
	# end of gps time list
    done
    # end of channel list
    # Submit job into condor.

    echo job_${nametime}.sdf
    condor_submit job_${nametime}.sdf
    echo job_${namespectrum}.sdf
    condor_submit job_${namespectrum}.sdf
    echo job_${namespectrogram}.sdf
    condor_submit job_${namespectrogram}.sdf
    echo job_${namecoherencegram}.sdf
    condor_submit job_${namecoherencegram}.sdf

done
# end of parameter.txt

