#!/bin/bash

################################################################
# This file is for submitting trigger related plot job into condor.
#
# Recommendation: 
# 
# In python script, package Kozapy/samples/mylib/ is reuired.
# Please make symbolic link in your working directory like this. 
# $ ln -s /path/to/Kozapy/samples/mylib/ mylib
#
################################################################

# Define variables.

nametime="timeseries"
namespectrum="spectrum"
namespectrogram="whitening_spectrogram"
namecoherencegram="coherencegram"
nameqtransform="qtransform"
namelock="locksegments"

cat $1 | while read gpstime channel min_duration max_duration bandwidth maxSNR frequency_snr max_amp frequency_amp eventtype triggertype
do
    echo "gps time = $gpstime "
    echo "channel = $channel "
    echo "min_duration = $min_duration "
    echo "max_duration = $max_duration "
    echo "bandwidth = $bandwidth "

    # $index will be added to the output file name to distinguish from others. 
    index=$eventtype"_"$gpstime"_"$channel

    # channel list file can be generated by hand or by chlist.sh.
    # chlist.sh will not rewrite existing file. 

    channels=$channel".dat"
    ./chlist_plotter.sh $channels $channel

    # For timeseries, gps time start from 2s before glitch and end at 2s after glitch.

    # For spectrum, spectogram, and coherencegram,
    # fftlength is defined based on bandwidth of the trigger event.
    # For spectrum, fft length = 1/bandwidth, rounded to integer.
    fft30=`echo "scale=5; 1. / $bandwidth" | bc | awk '{printf("%d\n",$1 + 1)}'`
    # select fft to take 2^n data points.
    tmp=`awk "BEGIN {print log($fft30) / log(2)}"`
    dif=0
    if [ "$(echo "$tmp < 0" | bc)" -eq 1 ]; then
#	tmp2=`echo $tmp | awk '{printf("%i\n", $tmp + 16)}'`
	tmp2=0
#	fft30=${sampling[tmp2]}
    else
	tmp2=`echo $tmp | awk '{printf("%i\n", $tmp )}'`
    fi

    fft30=`awk "BEGIN {print 2**$tmp2}"`

    if [ "$(echo "$fft30 > 30" | bc)" -eq 1 ]; then
	fft30=16
    fi 

    # determine time scale to use. around 30s, use a nice round number.
    # divide is number of bins. 
    ndivide30=`echo "scale=5; 30. / $fft30" | bc | awk '{printf("%d\n",$1 + 1)}'`
    # span is total data length.
    span30=`echo "scale=5; $fft30 * $ndivide30" | bc `

    echo fft30 $fft30
    echo ndivide30 $ndivide30
    echo span30 $span30

    # for spectrogram etc.
    # fft length = larger one of [min_duration] or [max_duration/10]
    # stride = multiple of fft length, 

    # 
    fft=`echo "scale=5; $max_duration / 10. " | bc `

    if [ "$(echo "$fft < $min_duration" | bc)" -eq 1 ]; then
	fft=$min_duration
    fi
    echo fft $fft

    # select fft to take 2^n data points.
    sampling=( 1 0.5 0.25 0.125 0.0625 0.03125 0.015625 0.0078125 0.0390625 0.001953125 0.00097656250 0.00048828125 0.000244140625 0.000122703125 0.00006103515625 )
    tmp=`awk "BEGIN {print log($fft) / log(2)}"`
    dif=0

    if [ "$(echo "$tmp < 0" | bc)" -eq 1 ]; then
	tmp2=`echo "scale=0; 0 - ${tmp} "| bc | awk '{printf("%d\n",$1 + 1)}'`
	fft=${sampling[$tmp2]}
	while [ "$(echo "scale=5; $fft < 1. / ${frequency_snr}" | bc)" -eq 1 ]
	do
	    tmp2=$(($tmp2 - 1))
	    fft=${sampling[$tmp2]}
	done
    else
	tmp2=`echo "scale=0; $tmp "| bc | awk '{printf("%d\n",$1 )}'`
	fft=`awk "BEGIN {print 2**$tmp2}"`
	while [ "$(echo "scale=5; $fft < 1. / ${frequency_snr}" | bc)" -eq 1 ]
	do
	    tmp2=$(($tmp2 + 1))
	    fft=`awk "BEGIN {print 2**$tmp2}"`
	done
    fi

    # stride is minimum of a and b.

    a=`echo "scale=5; $min_duration * 10. " | bc `
    b=`echo "scale=5; $max_duration / 2. " | bc `
    stride=0
    span=0

    if [ "$(echo "$b < $a" | bc)" -eq 1 ]; then
	stride=$b
    else
	stride=$a
    fi

    divide=`echo "scale=5; $stride / $fft" | bc | awk '{printf("%d\n",$1 + 2)}'`

    # make the stride to be multiple of fft length.
    stride=`echo "scale=5; $fft * $divide" | bc `

    # make the time span to be multiple of stride.
    span=`echo "scale=5; $max_duration * 10 " | bc `
    if [ "$(echo "$span < 2.0" | bc)" -eq 1 ]; then
	span=2.
    fi

    divide=`echo "scale=5; $span / $stride" | bc | awk '{printf("%d\n",$1 + 1)}'`

    span=`echo "scale=5; $stride * $divide" | bc | awk '{printf("%d\n",$1 + 1)}'`

    echo fft $fft
    echo divide $divide
    echo span $span

    tmpend=`echo "scale=5; $span30 + 2. " | bc `

    #    gpsstart=`expr $gpstime - 30`
#    gpsend=`expr $gpstime + 30`

    gpsstart=`echo "scale=5; $gpstime - $span " | bc `
    gpsend=`echo "scale=5; $gpstime + $span " | bc `

    if [ "$(echo "$span > 30.0" | bc)" -eq 1 ]; then
	span=30.
    fi

    qgpsstart=`echo "scale=5; $gpstime - $span " | bc `
    qgpsend=`echo "scale=5; $gpstime + $span " | bc `


    # after trigger
    gpsstart1=`echo "scale=5; $gpstime + 2. + $max_duration " | bc | awk '{printf("%d\n",$1 + 1)}'`
    gpsend1=`echo "scale=5; $gpstime + $span30 + 2. +$max_duration " | bc | awk '{printf("%d\n",$1 + 1)}'`
    #before trigger
    gpsstart2=`echo "scale=5; $gpstime - $span30 - 2. " | bc | awk '{printf("%d\n",$1 - 1)}'`
    gpsend2=`echo "scale=5; $gpstime - 2. " | bc | awk '{printf("%d\n",$1 - 1)}'`
    # during trigger
    #gpsstart3=$gpstime
    #gpsend3=`echo "scale=5; $gpstime + $max_duration " | bc `

    gpsstarts30=($gpsstart1 $gpsstart2)
    gpsends30=($gpsend1 $gpsend2)

    # Data type for time series. Default is to use minutes trend. second trend or full data can be used with following flags. Please set one of them true and set the others false. Or it will give warning message and exit. 
    #data="minute"
    #data="second"
    data="full"

    if [ `hostname` == "k1sum1" ]; then
	kamioka=true
    else
	kamioka=false
    fi
    #kamioka=true
    #kamioka=false

    # For locked segments bar plot.
    lock=true
    #lock=false

    # IMC lock
    #lchannel="K1:GRD-IO_STATE_N.mean"  #guardian channel
    #lchannel="K1:GRD-IO_STATE_N"  #guardian channel
    #lnumber=99  #number of the required state
    #llabel='IMC_LSC'  #y-axis label for the bar plot.

    # X-arm lock
#    lchannel="K1:GRD-LSC_LOCK_STATE_N"  #guardian channel
#    lnumber=31415  #number of the required state
#    llabel='X-arm'  #y-axis label for the bar plot.

    #  lock
    lchannel="K1:GRD-LSC_LOCK_STATE_N"  #guardian channel
    lnumber=157  #number of the required state
    llabel='LSC'  #y-axis label for the bar plot.

    
    # Set the output directory.
#    condir="/users/.ckozakai/KashiwaAnalysis/analysis/code/gwpy/trigger/plotter"

    if "${kamioka}"; then
	condir="/users/DET/Result/GlitchPlot"
    else
	condir="/home/chihiro.kozakai/public_html/KAGRA/GlitchPlot"
    fi

    if [ "$condir" = "" ]; then
	condir=$PWD
    fi

    if "${kamioka}"; then
	[ -e /usr/bin/gpstime ] && cmd_gps=/usr/bin/gpstime || cmd_gps=/home/controls/bin/gpstime
	date=`${cmd_gps} ${gpstime}| head -1`
	set ${date}
	date=`echo ${2}| sed -e 's/-//g'`
    else
	date=`tconvert -l -f %Y%m%d ${gpstime}`
    fi

    outdir="$condir/$date/${index}/"

    # Confirm the existance of output directory.

    if [ ! -e $outdir ]; then
	mkdir -p $outdir
    fi

    {
	echo $gpstime $channel $min_duration $max_duration $bandwidth $maxSNR $frequency_snr $max_amp $frequency_amp  $eventtype $triggertype
    } > $outdir/parameter.txt

    logdir="$PWD/log/$date/"
    if [ ! -e $logdir ]; then
	mkdir -p $logdir
    fi

    # make main script.

    # for time series.

    if "${kamioka}"; then
	Kozapy="/users/DET/tools/GlitchPlot/Script/Kozapy/samples"
    else
	Kozapy="/home/chihiro.kozakai/detchar/analysis/code/gwpy/Kozapy/samples"
    fi

    runtime="$PWD/run_${nametime}.sh"
    pytime="$Kozapy/batch_${nametime}.py"
    #py="~/batch_timesries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo timeseries"
#	echo "echo \$@"
#	echo "python $pytime \$@"
#	
#   } > $runtime

#    chmod u+x $runtime

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runtime}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${nametime}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${nametime}.sdf

    # for spectrum series.
    
    runspectrum="$PWD/run_${namespectrum}.sh"
    pyspectrum="$Kozapy/batch_${namespectrum}.py"
    #py="~/batch_spectrumsries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo spectrum"
#	echo "echo \$@"
#	echo "python $pyspectrum \$@"
#	
#    } > $runspectrum

#    chmod u+x $runspectrum

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runspectrum}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${namespectrum}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${namespectrum}.sdf

    # for spectrogram series.
    
    runspectrogram="$PWD/run_${namespectrogram}.sh"
    pyspectrogram="$Kozapy/batch_${namespectrogram}.py"
    #py="~/batch_spectrogramsries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo whitening_spectrogram"
#	echo "echo \$@"
#	echo "python $pyspectrogram \$@"
#	
#    } > $runspectrogram

#    chmod u+x $runspectrogram

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runspectrogram}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${namespectrogram}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${namespectrogram}.sdf

    # for coherencegram series.
    
    runcoherencegram="$PWD/run_${namecoherencegram}.sh"
    pycoherencegram="$Kozapy/batch_${namecoherencegram}.py"
    #py="~/batch_coherencegramsries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo coherencegram"
#	echo "echo \$@"
#	echo "python $pycoherencegram \$@"
#	
#    } > $runcoherencegram

#    chmod u+x $runcoherencegram

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runcoherencegram}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${namecoherencegram}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${namecoherencegram}.sdf

    # for qtransform.
    
    runqtransform="$PWD/run_${nameqtransform}.sh"
    pyqtransform="$Kozapy/batch_${nameqtransform}.py"
    #py="~/batch_qtransformsries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo qtransform"
#	echo "echo \$@"
#	echo "python $pyqtransform \$@"
	
#    } > $runqtransform

#    chmod u+x $runqtransform

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runqtransform}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 8 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${nameqtransform}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${nameqtransform}.sdf

    # for lock segmnet.
    
    runlock="$PWD/run_${namelock}.sh"
    pylock="$Kozapy/batch_${namelock}.py"
    #py="~/batch_qtransformsries.py"  # For the case you use non-conventional python script name.

#    {
#	echo "#!/bin/bash"
#	echo ""
#	echo "# PLEASE NEVER CHANGE THIS FILE BY HAND."
#	echo "# This file is generated from `basename $0`."
#	echo "# If you need to change, please edit `basename $0`."
#	echo ""
#	echo "echo locksegments"
#	echo "echo \$@"
#	echo "python $pylock \$@"
#	
#    } > $runlock

#    chmod u+x $runlock

    # Write a file for condor submission.
    
    {
	echo "PWD = $Fp(SUBMIT_FILE)"
	echo "transfer_input_files = rm_if_empty.sh"
	echo '+PostCmd = "rm_if_empty.sh"'
	echo '+PostArguments = "_condor_stderr _condor_stdout $(PWD)$(Output) $(PWD)$(Error) $(PWD)/$(Log)"'
	echo "Executable = ${runlock}"
	echo "Universe   = vanilla"
	echo "Notification = never"
	# if needed, use following line to set the necessary amount of the memory for a job. In Kashiwa, each node has total memory 256 GB, 2 CPU, 28 cores.
	echo "request_memory = 1 GB"
	echo "Getenv  = True            # the environment variables will be copied."
	echo ""
	echo "should_transfer_files = YES"
	echo "when_to_transfer_output = ON_EXIT"
	echo ""
	echo "Log          = log/$date/log_${namelock}.txt"
	echo "Output       = log/$date/\$(Cluster).\$(Process).out"
	echo "Error       = log/$date/\$(Cluster).\$(Process).err"
	echo ""
    } > job_${namelock}.sdf

    {
	# Please try
	#  $ python batch_locksegments.py -h
	# for option detail.
	
	echo "Arguments = -s $gpsstart -e $gpsend -o ${outdir} -i $channel -t $gpstime -d $max_duration "
	echo "Queue"
    } >> job_${namelock}.sdf
	
    echo job_${namelock}.sdf
    condor_submit job_${namelock}.sdf

    # Loop over each plot. 
    option=""
    if "${kamioka}" ; then
	option+=" -k"
    fi

    optionspectrum=$option
    optioncoherencegram=$option
    
    if "${lock}" ; then
	option+=" -l ${lchannel} -n ${lnumber} --llabel ${llabel}"
    else
	echo "lock is false."
    fi

    optionspectrogram=$option
    optionqtransform=$option
    
    if [ $data = "minute" ] ; then
	option+=" -d minute"
    elif [ $data = "second" ] ; then
	option+=" -d second"
    elif [ $data = "full" ] ; then
	option+=" -d full"
    fi

    optiontime=$option

    cat $channels | while read chlist
    do
	# timeseries job
	{
	    # Please try
	    #  $ python batch_timeseries.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s $gpsstart -e $gpsend -o ${outdir} -i $channel ${optiontime} -t '${chlist[0]}_Timeseries' --nolegend --dpi 50"
	    echo "Queue"
	} >> job_${nametime}.sdf

	# If low sampling channel, only time series plot will be made. 
	if [ "`echo ${chlist[@]} | grep _OUTPUT `" ]; then
	    continue
	fi

	# coherencegram job
	{
	    # Please try
	    #  $ python batch_coherencegram.py -h
	    # for option detail.
	    
	    echo "Arguments = -r $channel -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i $channel -f ${fft} --stride ${stride} ${optioncoherencegram} --dpi 50"
	    echo "Queue"

#	    echo "Arguments = -r $channel -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i $channeldur -f ${duration} --stride ${durstride} ${optioncoherencegram}"
#	    echo "Output       = log/$date/out_\$(Cluster).\$(Process).txt"
#	    echo "Error        = log/$date/err_\$(Cluster).\$(Process).txt"
#	    echo "Log          = log/$date/log_\$(Cluster).\$(Process).txt"
#	    echo "Queue"
	} >> job_${namecoherencegram}.sdf


	# spectrum job
	{
	    # Please try
	    #  $ python batch_spectrum.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s ${gpsstarts30[@]} -e ${gpsends30[@]} -o ${outdir} -i $channel -t time -f ${fft30} ${optionspectrum} --dpi 50"
	    echo "Queue"
	} >> job_${namespectrum}.sdf

	# spectrogram job
	{
	    # Please try
	    #  $ python batch_ehitening_spectrogram.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i $channel -f ${fft} --stride ${stride} ${optionspectrogram} --dpi 50"
	    echo "Queue"

	    echo "Arguments = -c ${chlist[@]} -s ${gpsstart} -e ${gpsend} -o ${outdir} -i $channel -f ${fft} --stride ${stride} ${optionspectrogram} -w"
	    echo "Queue"


	} >> job_${namespectrogram}.sdf


	# qtransform job
	{
	    # Please try
	    #  $ python batch_coherencegram.py -h
	    # for option detail.
	    
	    echo "Arguments = -c ${chlist[@]} -s ${qgpsstart} -e ${qgpsend} -o ${outdir} -i $channel ${optionqtransform} --dpi 50"
	    echo "Queue"

	} >> job_${nameqtransform}.sdf

#	done
	# end of gps time list

    done
    # end of channel list
    # Submit job into condor.
    echo job_${nametime}.sdf
    condor_submit job_${nametime}.sdf
    echo job_${namespectrum}.sdf
    condor_submit job_${namespectrum}.sdf
    echo job_${namespectrogram}.sdf
    condor_submit job_${namespectrogram}.sdf
    echo job_${namecoherencegram}.sdf
    condor_submit job_${namecoherencegram}.sdf
    echo job_${nameqtransform}.sdf
    condor_submit job_${nameqtransform}.sdf

done
# end of parameter.txt

